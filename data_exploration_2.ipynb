{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowload data\n",
    "Let's download the wikimedia page counts data of 2016-08-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ubuntu/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /Users/mohamed-aminezghal/Documents/streaming_algorithms/code/data: File exists\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 113232.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# create dir data\n",
    "! mkdir \"$DATA_PATH\"\n",
    "\n",
    "os.chdir(DATA_PATH)\n",
    "\n",
    "# download one day wikimedia data, date=2016-08-01\n",
    "prefix = \"https://dumps.wikimedia.org/other/pagecounts-raw/2016/2016-08/pagecounts-20160801-\"\n",
    "for i in tqdm(range(24)):\n",
    "    url = \"\".join([prefix, \"{:02}0000\".format(i), \".gz\"])\n",
    "    ! wget \"$url\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pagecounts-20160801-000000.gz pagecounts-20160801-120000.gz\r\n",
      "pagecounts-20160801-010000.gz pagecounts-20160801-130000.gz\r\n",
      "pagecounts-20160801-020000.gz pagecounts-20160801-140000.gz\r\n",
      "pagecounts-20160801-030000.gz pagecounts-20160801-150000.gz\r\n",
      "pagecounts-20160801-040000.gz pagecounts-20160801-160000.gz\r\n",
      "pagecounts-20160801-050000.gz pagecounts-20160801-170000.gz\r\n",
      "pagecounts-20160801-060000.gz pagecounts-20160801-180000.gz\r\n",
      "pagecounts-20160801-070000.gz pagecounts-20160801-190000.gz\r\n",
      "pagecounts-20160801-080000.gz pagecounts-20160801-200000.gz\r\n",
      "pagecounts-20160801-090000.gz pagecounts-20160801-210000.gz\r\n",
      "pagecounts-20160801-100000.gz pagecounts-20160801-220000.gz\r\n",
      "pagecounts-20160801-110000.gz pagecounts-20160801-230000.gz\r\n"
     ]
    }
   ],
   "source": [
    "! ls \"$DATA_PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We have downloaded 24 files. Each file contains page counts for one hour of 2016-08-01 in teh folowing format:__\n",
    "\n",
    "/projectcounts-${YEAR}${MONTH}-${DAY}-${HOUR}0000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosse a file number (similar to choosing hour of day between 0 to 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first lines of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa File:Sleeping_lion.jpg 1 8030\r\n",
      "aa Main_Page 1 78261\r\n",
      "aa Special:Statistics 1 20493\r\n",
      "aa Special:WhatLinksHere/File:Crystal_Clear_app_email.png 1 5412\r\n",
      "aa Special:WhatLinksHere/File:Wikipedia-logo-fr.png 1 5370\r\n",
      "aa Steward_requests/Bot_status 1 4733\r\n",
      "aa Translation_teams/ru 1 4718\r\n",
      "aa User:%E5%8F%B8%E5%BE%92%E4%BC%AF%E9%A2%9C 2 20096\r\n",
      "aa User:149.62.201.0/24 1 4802\r\n",
      "aa User:191.101.30.0/24 1 4806\r\n"
     ]
    }
   ],
   "source": [
    "prefix = \"pagecounts-20160801-\"\n",
    "# fname stores the filename without the \".gz\"\n",
    "fname = prefix + \"{:02}0000\".format(file_number)\n",
    "# unzip the file, while keeping the compressed file\n",
    "! gunzip -k \"$fname\".gz\n",
    "# compute the number of lines with bash command wc -l and store the result in wcout\n",
    "lines_count = ! wc -l \"$fname\"\n",
    "# get the first lines of the file\n",
    "! head \"$fname\"\n",
    "# Delete the uncompressed file\n",
    "! rm \"$fname\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first field is ```domain_name``` (ex: aa), the second field is ```page_title``` (ex: Main_Page), the third field is ```count_views``` (ex: 1) and the last field is ```total_response_size``` (ex: 78261). So for example ```en Main_Page 42 50043``` means 42 requests to en.wikipedia.org/wiki/Main_Page, which accounted in total for 50043 response bytes.\n",
    "More info: https://wikitech.wikimedia.org/wiki/Analytics/Archive/Data/Pagecounts-raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 6270942 pagecounts-20160801-000000']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file pagecounts-20160801-000000 contains __6 270 942__ lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you answer the following questions:\n",
    "- Are the lines ordered in a certain manner? Yes. Alphanumerical order.\n",
    "- What is the most viewed (```damain_name```, ```page_title```) couple in the file pagecounts-20160801-000000?\n",
    "- Which (```damain_name```, ```page_title```) couple in the file pagecounts-20160801-000000 has the largest ```total_response_size```?\n",
    "- What is the most visited ```domain_name```?\n",
    "- Which files have the highest and lowest number of lines?\n",
    "- What is the total number of lines across all files?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the most viewed (```damain_name```, ```page_title```) couple in the file pagecounts-20160801-000000?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(en.mw, en) is the most viewed (domain_name, page_title) with 5336925 views\n"
     ]
    }
   ],
   "source": [
    "file_number = 0\n",
    "prefix = \"pagecounts-20160801-\"\n",
    "fname = prefix + \"{:02}0000\".format(file_number)\n",
    "! gunzip -k \"$fname\".gz\n",
    "max_count_views, max_domain_name, max_page_title = 0, None, None\n",
    "# Read file and extract fields\n",
    "file = open(fname, \"r\", encoding='utf-8')\n",
    "for line in file:\n",
    "    domain_name, page_title, count_views, total_response_size = line.split(' ')\n",
    "    count_views = int(count_views)\n",
    "    if count_views > max_count_views:\n",
    "        max_count_views = count_views\n",
    "        max_domain_name = domain_name\n",
    "        max_page_title = page_title\n",
    "! rm \"$fname\"\n",
    "\n",
    "print(\"({domain_name}, {page_title}) is the most viewed (domain_name, page_title) with {count_views} views\".format(\n",
    "    domain_name=max_domain_name,\n",
    "    page_title=max_page_title,\n",
    "    count_views=max_count_views))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Which (```damain_name```, ```page_title```) couple in the file pagecounts-20160801-000000 has the largest ```total_response_size```?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(en.mw, en) couple has the largest total_response_size: 122044585824 views\n"
     ]
    }
   ],
   "source": [
    "file_number = 0\n",
    "prefix = \"pagecounts-20160801-\"\n",
    "fname = prefix + \"{:02}0000\".format(file_number)\n",
    "! gunzip -k \"$fname\".gz\n",
    "max_total_response_size, max_domain_name, max_page_title = 0, None, None\n",
    "# Read file and extract fields\n",
    "file = open(fname, \"r\", encoding='utf-8')\n",
    "for line in file:\n",
    "    domain_name, page_title, count_views, total_response_size = line.split(' ')\n",
    "    total_response_size = int(total_response_size)\n",
    "    if total_response_size > max_total_response_size:\n",
    "        max_total_response_size = total_response_size\n",
    "        max_domain_name = domain_name\n",
    "        max_page_title = page_title\n",
    "! rm \"$fname\"\n",
    "\n",
    "print(\"({domain_name}, {page_title}) couple has the largest total_response_size: {total_response_size} views\".format(\n",
    "    domain_name=max_domain_name,\n",
    "    page_title=max_page_title,\n",
    "    total_response_size=max_total_response_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the most visited ```domain_name```?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en is the most viewed domain_name with 6949620 views\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "file_number = 0\n",
    "prefix = \"pagecounts-20160801-\"\n",
    "fname = prefix + \"{:02}0000\".format(file_number)\n",
    "! gunzip -k \"$fname\".gz\n",
    "domain_name_counts = defaultdict(int)\n",
    "# Read file and extract fields\n",
    "file = open(fname, \"r\", encoding='utf-8')\n",
    "for line in file:\n",
    "    domain_name, page_title, count_views, total_response_size = line.split(' ')\n",
    "    domain_name_counts[domain_name] += int(count_views)\n",
    "    \n",
    "max_count_views, max_domain_name = 0, None\n",
    "for domain_name, count_views in domain_name_counts.items():\n",
    "    if count_views > max_count_views:\n",
    "        max_count_views = count_views\n",
    "        max_domain_name = domain_name\n",
    "    \n",
    "! rm \"$fname\"\n",
    "\n",
    "print(\"{domain_name} is the most viewed domain_name with {count_views} views\".format(\n",
    "    domain_name=max_domain_name,\n",
    "    count_views=max_count_views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:46<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "files_lines_count = []\n",
    "for file_number in tqdm(range(24)):\n",
    "    prefix = \"pagecounts-20160801-\"\n",
    "    fname = prefix + \"{:02}0000\".format(file_number)\n",
    "    ! gunzip -k \"$fname\".gz\n",
    "    lines_count = ! wc -l \"$fname\"\n",
    "    # store lines_count\n",
    "    files_lines_count.extend(lines_count)\n",
    "    ! rm \"$fname\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Which files have the highest and lowest number of lines?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File pagecounts-20160801-150000 has the maximum number of lines 7846121\n",
      "File pagecounts-20160801-020000 has the minimum number of lines 5838509\n"
     ]
    }
   ],
   "source": [
    "max_lines, max_file = 0, None\n",
    "min_lines, min_file = 6270942, None\n",
    "for lines_count in files_lines_count:\n",
    "    _, nb_lines_str, file_name = lines_count.split(' ')\n",
    "    nb_lines = int(nb_lines_str)\n",
    "    if nb_lines > max_lines:\n",
    "        max_lines = nb_lines\n",
    "        max_file = file_name\n",
    "    if nb_lines < min_lines:\n",
    "        min_lines = nb_lines\n",
    "        min_file = file_name\n",
    "        \n",
    "print(\"File {file_name} has the maximum number of lines {nb_lines}\".format(\n",
    "    file_name=max_file,\n",
    "    nb_lines=max_lines))\n",
    "print(\"File {file_name} has the minimum number of lines {nb_lines}\".format(\n",
    "    file_name=min_file,\n",
    "    nb_lines=min_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What is the total number of lines across all files?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 164306459 lines across all files\n"
     ]
    }
   ],
   "source": [
    "total_lines_count = sum([int(lines_count.split(' ')[1]) for lines_count in files_lines_count])\n",
    "print(\"There are {total_lines_count} lines across all files\".format(total_lines_count=total_lines_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
